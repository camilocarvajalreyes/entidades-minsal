{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo de modelo BERT para detección de entidades\n",
    "\n",
    "En este notebook:\n",
    "- Mostramos como cargar nuestros modelos usando HuggingFace\n",
    "- Transformamos su output a etiquetas de entidades interpretables\n",
    "\n",
    "Su objetivo es ejecutar los algoritmos desde cero teniendo sólamente un ambiente conda. Su público objetivo es alguien que se interese en como los modelos tratan los datos. Si el objetivo es únicamente probar el modelo en un input de manera directa ver el notebook **demo_minimalista.ipynb** (que sin embargo requiere instalación previa). Notar que este no fue el mismo ambiente con el cual desarrollamos el proyecto, i.e., este notebook requiere unicamente un ambiente python sin ninguna dependencia instalada previamente.\n",
    "\n",
    "Fue probado en una máquina linux con ambiente conda instalado, versión de python 3.9.0. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.20.0 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (1.20.0)\n",
      "Collecting pandas==1.4.3\n",
      "  Using cached pandas-1.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from pandas==1.4.3) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from pandas==1.4.3) (1.20.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from pandas==1.4.3) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.4.3) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.3\n",
      "    Uninstalling pandas-1.2.3:\n",
      "      Successfully uninstalled pandas-1.2.3\n",
      "Successfully installed pandas-1.4.3\n",
      "Collecting scipy==1.9.1\n",
      "  Using cached scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from scipy==1.9.1) (1.20.0)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.3\n",
      "    Uninstalling scipy-1.9.3:\n",
      "      Successfully uninstalled scipy-1.9.3\n",
      "Successfully installed scipy-1.9.1\n"
     ]
    }
   ],
   "source": [
    "# instalación de bibliotecas necesarias\n",
    "!pip install numpy==1.20.0\n",
    "!pip install pandas==1.4.3\n",
    "!pip install scipy==1.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 887.4 MB 40 kB/s  eta 0:00:0116\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 34 kB/s  eta 0:00:012\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 92 kB/s s eta 0:00:01     |█████████████▊                  | 136.4 MB 382 kB/s eta 0:07:53\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.36.2)\n",
      "Requirement already satisfied: setuptools in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (52.0.0.post20210125)\n",
      "Installing collected packages: nvidia-cublas-cu11, typing-extensions, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 typing-extensions-4.4.0\n",
      "Collecting transformers==4.23.1\n",
      "  Using cached transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from transformers==4.23.1) (20.9)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 253 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from transformers==4.23.1) (2.25.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from transformers==4.23.1) (1.20.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.23.1) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from requests->transformers==4.23.1) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from requests->transformers==4.23.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from requests->transformers==4.23.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/camilo/miniconda3/envs/agro/lib/python3.9/site-packages (from requests->transformers==4.23.1) (2.10)\n",
      "Installing collected packages: tqdm, pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.2 huggingface-hub-0.11.1 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip install transformers==4.23.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7834a7e52c3f48bdb814d0d17ee90fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132d96c58bd2408086a43b23c928a373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb41a4b2f35c41528106b6dd4463364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/735k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ba724143914f469e55b1a86451284a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d957d4dac14fba80abbc4e7fa7d10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965afed42e54bbe9bc6e1853ab4ee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/437M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "MODEL = 'ccarvajal/beto-prescripciones-medicas'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL, num_labels=11, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ambos tokenizer y modelos, se puede guardar una copia local usando el método .save_pretrained()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output del modelo\n",
    "\n",
    "Definimos dos funciones auxiliares que nos ayudarán con el etiquetado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "def word_ids_method(text,tokenizer):\n",
    "    \"\"\"Método que asigna el primer token (subword) de una palabra como representante\n",
    "        La etiqueta de este token será la etiqueta de la palabra\n",
    "    Método integrado en tokenize_and_align_labels\n",
    "    Fuente: https://huggingface.co/docs/transformers/tasks/token_classification\n",
    "\n",
    "    Argumentos\n",
    "\n",
    "        text: str o List[str]\n",
    "            texto a tokenizar, si \n",
    "    \"\"\"\n",
    "    if not isinstance(text,list):\n",
    "        text = text.split()\n",
    "    n_words = len(text)\n",
    "\n",
    "    tokenized_inputs = tokenizer([text], truncation=True, is_split_into_words=True)\n",
    "    mask = []\n",
    "    # for i in range(n_words):\n",
    "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            mask.append(0)\n",
    "        elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "            mask.append(1)\n",
    "        else:\n",
    "            mask.append(0)\n",
    "        previous_word_idx = word_idx\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def eval_text(text,tokenizer,model):\n",
    "    \"\"\"\n",
    "    Toma un texto (lista de palabras o string), un tokenizador y modelo de HuggingFace\n",
    "    Retorna el output del modelo (ids de entidades)\n",
    "    \"\"\"\n",
    "    mask = word_ids_method(text,tokenizer)\n",
    "    encoded_input = tokenizer(text,return_tensors='pt',is_split_into_words=isinstance(text,list))\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    result = np.argmax(scores,axis=1)\n",
    "\n",
    "    return result[mask==np.array(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARACETAMOL 500 MG COMPRIMIDO 1 COMPRIMIDO ORAL cada 6 horas durante 3 dias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9, 10, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"PARACETAMOL 500 MG COMPRIMIDO 1 COMPRIMIDO ORAL cada 6 horas durante 3 dias\"\n",
    "\n",
    "print(text)\n",
    "eval_text(text,tokenizer,model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos ya un output de nuestro modelo con cinco entidades, sin embargo nos gustaría tener las entidades con sus respectivas etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dict = {'O': 0,\n",
    "            'B-ACTIVE_PRINCIPLE': 1,\n",
    "            'I-ACTIVE_PRINCIPLE': 2,\n",
    "            'B-FORMA_FARMA':3,\n",
    "            'I-FORMA_FARMA':4,\n",
    "            'B-ADMIN': 5,\n",
    "            'I-ADMIN': 6,\n",
    "            'B-PERIODICITY': 7,\n",
    "            'I-PERIODICITY': 8,\n",
    "            'B-DURATION': 9,\n",
    "            'I-DURATION': 10\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_entities(y_pred,map_dict,return_type='list'):\n",
    "    inv_map = {v: k for k, v in map_dict.items()}\n",
    "    if return_type == 'list':\n",
    "        return [inv_map[y] for y in y_pred]\n",
    "    else:\n",
    "        return np.array([inv_map[y] for y in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARACETAMOL\tB-ACTIVE_PRINCIPLE\n",
      "500\tB-FORMA_FARMA\n",
      "MG\tI-FORMA_FARMA\n",
      "COMPRIMIDO\tI-FORMA_FARMA\n",
      "1\tB-ADMIN\n",
      "COMPRIMIDO\tI-ADMIN\n",
      "ORAL\tI-ADMIN\n",
      "cada\tB-PERIODICITY\n",
      "6\tI-PERIODICITY\n",
      "horas\tI-PERIODICITY\n",
      "durante\tB-DURATION\n",
      "3\tI-DURATION\n",
      "dias\tI-DURATION\n"
     ]
    }
   ],
   "source": [
    "entidades = map_entities(eval_text(text,tokenizer,model),ner_dict)\n",
    "for i, ent in enumerate(entidades):\n",
    "    print(\"{}\\t{}\".format(text.split()[i],ent))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Modelo para etiquetas ADMIN más finas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c332d2f6d2214b518ed14480babe41c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde82564f9e4d6380340f1fa9efb7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d37bd0eb82450abf085d1bf022fca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/735k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed408ee0c4ef4413bb2071bc1c85080d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b0dbe81fd14407b3f7c6c1a7643dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2e0eef8f904a96a47f1f575f7559d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/437M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_admin = 'ccarvajal/beto-prescripciones-medicas-ADMIN'\n",
    "\n",
    "tokenizer_admin = AutoTokenizer.from_pretrained(MODEL_admin)\n",
    "model_admin = AutoModelForTokenClassification.from_pretrained(MODEL_admin, num_labels=7, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_ner_dict = {\n",
    "    'O': 0,\n",
    "    'B-CANT': 1,\n",
    "    'I-CANT': 2,\n",
    "    'B-UND':3,\n",
    "    'I-UND':4,\n",
    "    'B-VIA_ADMIN': 5,\n",
    "    'I-VIA_ADMIN': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admin(entidades:list,texto:str) -> str:\n",
    "    \"\"\"Retorna un substring correspondiente a aquellas entidades etiquetadas con admin y los indices donde esto ocurre\"\"\"\n",
    "    indices = [i for i, ent in enumerate(entidades) if ent == 'B-ADMIN' or ent == 'I-ADMIN']\n",
    "    return ' '.join([token for i, token in enumerate(texto.split(' ')) if i in indices]), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar(texto):\n",
    "    entidades = map_entities(eval_text(texto,tokenizer,model),ner_dict)\n",
    "    admin_text, indices = get_admin(entidades,texto)\n",
    "    entidades_admin = map_entities(eval_text(admin_text,tokenizer_admin,model_admin),admin_ner_dict)\n",
    "    for i, ent_admin in enumerate(entidades_admin):\n",
    "        entidades[indices[i]] = ent_admin\n",
    "    return entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARACETAMOL\tB-ACTIVE_PRINCIPLE\n",
      "500\tB-FORMA_FARMA\n",
      "MG\tI-FORMA_FARMA\n",
      "COMPRIMIDO\tI-FORMA_FARMA\n",
      "1\tB-CANT\n",
      "COMPRIMIDO\tB-UND\n",
      "ORAL\tB-VIA_ADMIN\n",
      "cada\tB-PERIODICITY\n",
      "6\tI-PERIODICITY\n",
      "horas\tI-PERIODICITY\n",
      "durante\tB-DURATION\n",
      "3\tI-DURATION\n",
      "dias\tI-DURATION\n"
     ]
    }
   ],
   "source": [
    "entidades = etiquetar(text)\n",
    "for i, ent in enumerate(entidades):\n",
    "    print(\"{}\\t{}\".format(text.split()[i],ent))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente mostramos una manera más bonita de mostrar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def render_pandas(ents,text_list):\n",
    "    data = {'ACTIVE_PRINCIPLE':'','FORMA_FARMA':'','CANT-ADMIN':'','UND-ADMIN':'','VIA-ADMIN':'','PERIODICITY':'','DURATION':''}\n",
    "\n",
    "    for i, ent in enumerate(ents):\n",
    "        if '-ACTIVE_PRINCIPLE' in ent:\n",
    "            data['ACTIVE_PRINCIPLE'] += ' ' + text_list[i]\n",
    "        elif '-FORMA_FARMA' in ent:\n",
    "            data['FORMA_FARMA'] += ' ' + text_list[i]\n",
    "        elif '-CANT' in ent:\n",
    "            data['CANT-ADMIN'] += ' ' + text_list[i]\n",
    "        elif '-UND' in ent:\n",
    "            data['UND-ADMIN'] += ' ' + text_list[i]\n",
    "        elif '-VIA_ADMIN' in ent:\n",
    "            data['VIA-ADMIN'] += ' ' + text_list[i]\n",
    "        elif '-PERIODICITY' in ent:\n",
    "            data['PERIODICITY'] += ' ' + text_list[i]\n",
    "        elif '-DURATION' in ent:\n",
    "            data['DURATION'] += ' ' + text_list[i]\n",
    "\n",
    "    df = pd.DataFrame([data])\n",
    "    return df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])]).hide(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_50261 th {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_50261\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_50261_level0_col0\" class=\"col_heading level0 col0\" >ACTIVE_PRINCIPLE</th>\n",
       "      <th id=\"T_50261_level0_col1\" class=\"col_heading level0 col1\" >FORMA_FARMA</th>\n",
       "      <th id=\"T_50261_level0_col2\" class=\"col_heading level0 col2\" >CANT-ADMIN</th>\n",
       "      <th id=\"T_50261_level0_col3\" class=\"col_heading level0 col3\" >UND-ADMIN</th>\n",
       "      <th id=\"T_50261_level0_col4\" class=\"col_heading level0 col4\" >VIA-ADMIN</th>\n",
       "      <th id=\"T_50261_level0_col5\" class=\"col_heading level0 col5\" >PERIODICITY</th>\n",
       "      <th id=\"T_50261_level0_col6\" class=\"col_heading level0 col6\" >DURATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_50261_row0_col0\" class=\"data row0 col0\" > PARACETAMOL</td>\n",
       "      <td id=\"T_50261_row0_col1\" class=\"data row0 col1\" > 500 MG COMPRIMIDO</td>\n",
       "      <td id=\"T_50261_row0_col2\" class=\"data row0 col2\" > 1</td>\n",
       "      <td id=\"T_50261_row0_col3\" class=\"data row0 col3\" > COMPRIMIDO</td>\n",
       "      <td id=\"T_50261_row0_col4\" class=\"data row0 col4\" > ORAL</td>\n",
       "      <td id=\"T_50261_row0_col5\" class=\"data row0 col5\" > cada 6 horas</td>\n",
       "      <td id=\"T_50261_row0_col6\" class=\"data row0 col6\" > durante 3 dias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f594242ed30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_pandas(entidades,text.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a09f83d747ddbee076343c75140ab6a5612c6071f1d1b8cd9bf117d48cfe15b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
