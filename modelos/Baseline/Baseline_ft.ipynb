{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27csY87GaSFO",
        "outputId": "83f602c5-c7e0-477d-d8e3-68498f307ae5",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Instalamos torchtext que nos facilitará la vida en el pre-procesamiento del formato ConLL.\n",
        "# !pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gzip\n",
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "\n",
        "from operator import attrgetter\n",
        "from torchtext import vocab, datasets ,data\n",
        "#from torchtext.legacy import data #, datasets\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "ng7wRGEyawjM"
      },
      "outputs": [],
      "source": [
        "# Garantizar reproducibilidad de los experimentos\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "3DcM_IjgCdzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(('text', <torchtext.data.field.Field object at 0x7f3adc16a470>), ('nertags', <torchtext.data.field.Field object at 0x7f3adc168130>))\n"
          ]
        }
      ],
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))\n",
        "\n",
        "print(fields)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  **SequenceTaggingDataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "HsHdGml62J21"
      },
      "outputs": [],
      "source": [
        "# train_data_ft, valid_data_ft, test_data_ft = datasets.SequenceTaggingDataset.splits(\n",
        "#     path=\"./\",\n",
        "#     train=\"corpus_recetas_train.txt\",\n",
        "#     validation=\"corpus_recetas_val.txt\",\n",
        "#     test=\"corpus_recetas_test.txt\",\n",
        "#     fields=fields,\n",
        "#     encoding=\"utf-8\",\n",
        "#     separator=\" \"\n",
        "# )\n",
        "\n",
        "train_data_ft, valid_data_ft, test_data_ft = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"corpus_train.txt\",\n",
        "    validation=\"corpus_val.txt\",\n",
        "    test=\"corpus_test_pred.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"utf-8\",\n",
        "    separator=\"-X- _ \" \n",
        "    # separator=\"-X-\"\n",
        ")\n",
        "\n",
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"corpus_ER_train.txt\",\n",
        "    validation=\"corpus_ER_test.txt\", # val y test son iguales pero no importa porque solo se usa val para entrenar, y luego se hace fine tuning con las variables ft\n",
        "    test=\"corpus_ER_test.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"utf-8\",\n",
        "    separator=\" \"\n",
        ")\n",
        "\n",
        "# train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "#     path=\"./\",\n",
        "#     train=\"corpus_ER_train_v2.txt\",\n",
        "#     validation=\"corpus_ER_test_v2.txt\", # val y test son iguales pero no importa porque solo se usa val para entrenar, y luego se hace fine tuning con las variables ft\n",
        "#     test=\"corpus_ER_test_v2.txt\",\n",
        "#     fields=fields,\n",
        "#     encoding=\"utf-8\",\n",
        "#     separator=\" \"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu7q3HCliia5",
        "outputId": "ed55cb56-d9d8-4a56-a63d-db5bd222c448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 85245\n",
            "Número de ejemplos de validación: 51182\n",
            "Número de ejemplos de test: 51182\n"
          ]
        }
      ],
      "source": [
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDRnhXAdFGL-"
      },
      "source": [
        "Visualizemos un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T023Ld4RaSF4",
        "outputId": "f660c744-ebec-4138-e573-e04526d27c7b",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('LORAZEPAM', 'B-ACTIVE_PRINCIPLE'),\n",
              " ('solución', 'B-FORMA_FARMA'),\n",
              " ('inyectable', 'I-FORMA_FARMA'),\n",
              " ('4', 'O'),\n",
              " ('MG/ML', 'O'),\n",
              " ('1', 'O'),\n",
              " ('UNIDAD', 'O'),\n",
              " ('INTRAVENOSA', 'B-ADMIN'),\n",
              " ('diaria', 'B-PERIODICITY')]"
            ]
          },
          "execution_count": 421,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### **Construir los vocabularios para el texto y las etiquetas**\n",
        "\n",
        "Los vocabularios son los objetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields. El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "id": "PBhp7WICiibL"
      },
      "outputs": [],
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data,train_data_ft)\n",
        "# NER_TAGS.build_vocab(train_data_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4OgUKM_iibO",
        "outputId": "694db208-63ad-4026-f035-47d37bd80574",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 5678\n",
            "Tokens únicos en NER_TAGS: 12\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4FeyL9nFnId",
        "outputId": "a486ba2a-d653-4839-ba12-ff1a1184f372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " 'O',\n",
              " 'I-PERIODICITY',\n",
              " 'B-PERIODICITY',\n",
              " 'B-ACTIVE_PRINCIPLE',\n",
              " 'B-FORMA_FARMA',\n",
              " 'B-ADMIN',\n",
              " 'I-FORMA_FARMA',\n",
              " 'I-DURATION',\n",
              " 'B-DURATION',\n",
              " 'I-ACTIVE_PRINCIPLE',\n",
              " 'I-ADMIN']"
            ]
          },
          "execution_count": 424,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "NER_TAGS.vocab.itos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5eSLm4diibR",
        "outputId": "7df5c5c1-b01a-48dd-fa38-11dee22df1a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('MG', 61740),\n",
              " ('ML', 55473),\n",
              " ('cada', 50536),\n",
              " ('horas', 47976),\n",
              " ('1', 44157),\n",
              " ('ORAL', 44050),\n",
              " ('AMPOLLA', 32629),\n",
              " ('solución', 30173),\n",
              " ('comprimido', 28550),\n",
              " ('FRASCO', 28149)]"
            ]
          },
          "execution_count": 425,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokens mas frecuentes (Será necesario usar stopwords, eliminar símbolos o nos entregan información (?) )\n",
        "TEXT.vocab.freqs.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "WDyNLMPz9duD"
      },
      "outputs": [],
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']\n",
        "# O_TAG_IDX2 = NER_TAGS.vocab.stoi[' O']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrYvF3X0sjWL"
      },
      "source": [
        "#### **Frecuencia de los Tags**\n",
        "\n",
        "Visualizemos rápidamente las cantidades y frecuencias de cada tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuXOsbJUiibh",
        "outputId": "90842a04-d80b-44d1-d0cc-a58d9436ebe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t703243\t54.1%\n",
            "I-PERIODICITY\t130090\t10.0%\n",
            "B-PERIODICITY\t80764\t 6.2%\n",
            "B-ACTIVE_PRINCIPLE\t75608\t 5.8%\n",
            "B-FORMA_FARMA\t74462\t 5.7%\n",
            "B-ADMIN\t74023\t 5.7%\n",
            "I-FORMA_FARMA\t73811\t 5.7%\n",
            "I-DURATION\t45030\t 3.5%\n",
            "B-DURATION\t22278\t 1.7%\n",
            "I-ACTIVE_PRINCIPLE\t19889\t 1.5%\n",
            "I-ADMIN\t1380\t 0.1%\n"
          ]
        }
      ],
      "source": [
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### DataLoaders\n",
        "\n",
        "Importante: si tienes problemas con la ram de la gpu, disminuye el tamaño de los batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB7cwLWpaSGs",
        "outputId": "c48241fb-7105-4b4a-e58f-b85efc2443d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32 #16  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test. Si van a hacer algún sort no puede ser sobre\n",
        "# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n",
        "# debe conservar el orden original para ser comparado con los golden_labels. \n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")\n",
        "\n",
        "train_iterator_ft, valid_iterator_ft, test_iterator_ft = data.BucketIterator.splits(\n",
        "    (train_data_ft, valid_data_ft, test_data_ft),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")\n",
        "\n",
        "# test_loader_df =  pd.read_csv(\"corpus_test.txt\", sep=\"\\n\", header=None)\n",
        "# test_loader = torch.utils.data.DataLoader(test_loader_df, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B21E1eAFId16"
      },
      "source": [
        "#### **Métricas de evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "9mUOOLEWiicU"
      },
      "outputs": [],
      "source": [
        "# Definimos las métricas\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # filtramos <pad> para calcular los scores.\n",
        "    # print('pad_idx: ', pad_idx)\n",
        "    # print(len(preds), len(y_true))\n",
        "    mask = [(y_true != pad_idx)] \n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).cpu().numpy()\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_pred = [[NER_TAGS.vocab.itos[v] for v in y_pred]]\n",
        "    y_true = [[NER_TAGS.vocab.itos[v] for v in y_true]]\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, mode='strict', zero_division=0)\n",
        "    precision = precision_score(y_true, y_pred, mode='strict', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, mode='strict', zero_division=0)\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hod516H1aSG2"
      },
      "source": [
        "### **Modelo Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "id": "rMPL08XqaSG3"
      },
      "outputs": [],
      "source": [
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx,\n",
        "                                      )\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self._init_weights\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        # Inicializamos los pesos como aleatorios\n",
        "        for name, param in m.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "        # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "        self.embedding.weight.data[UNK_IDX] = torch.zeros(self.embedding_dim)\n",
        "        self.embedding.weight.data[PAD_IDX] = torch.zeros(self.embedding_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "gkKeMSG5-X2u"
      },
      "outputs": [],
      "source": [
        "# Caergamos Glove o fast text\n",
        "FASTTEXT_FILE = \"glove300d.vec\"\n",
        "# Se descargan vectores glove o fasttext del github del dcc\n",
        "# https://github.com/dccuchile/spanish-word-embeddings\n",
        "\n",
        "if not os.path.exists(FASTTEXT_FILE):\n",
        "    print(f\"Descargando {FASTTEXT_FILE}\")\n",
        "    url = \"http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\"\n",
        "    #url = \"https://s06.imfd.cl/04/fasttext-sbwc.vec.gz\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    try:\n",
        "        with gzip.open(response.raw, \"rb\") as f_in:\n",
        "            with open(FASTTEXT_FILE, \"wb\") as f_out:\n",
        "                # Funcion para copiar de un file-like object a otro\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    except Exception as e:\n",
        "        os.remove(FASTTEXT_FILE)\n",
        "        raise e\n",
        "\n",
        " #dimensión es de 300 y tiene 855,380 vectores pre-entrenados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "WbUcstoE-dae"
      },
      "outputs": [],
      "source": [
        "embeddings = vocab.Vectors(FASTTEXT_FILE)\n",
        "TEXT.vocab.set_vectors(*attrgetter(\"stoi\", \"vectors\", \"dim\")(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "kqjY7bMr-lAd"
      },
      "outputs": [],
      "source": [
        "class Modelo1_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_weights.clone(), freeze = False)\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        #text = [sent len, batch size]\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "DRFzYrLPAC4y"
      },
      "outputs": [],
      "source": [
        "class Modelo2_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_weights.clone(), freeze = False)\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "        #self.relu = nn.ReLU()\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        #text = [sent len, batch size]\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "_w0CFjA8aSHU"
      },
      "outputs": [],
      "source": [
        "# Para crear la red debemos heredar desde nn.Module\n",
        "class GruNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "      super().__init__()\n",
        "\n",
        "      # Capa de embedding\n",
        "      self.embedding = nn.Embedding(input_dim,\n",
        "                                    embedding_dim,\n",
        "                                    padding_idx=pad_idx,\n",
        "                                    )\n",
        "      \n",
        "      # Capa GRU\n",
        "      self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout = dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n",
        "      # Capa de salida\n",
        "      self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "      #self.relu = nn.ReLU()\n",
        "      # Dropout\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Definimos las operaciones de las capas sobre el input en el forward.\n",
        "    def forward(self, text): \n",
        "      embedded = self.embedding(text)\n",
        "      outputs, hidden = self.gru(embedded)\n",
        "      predictions = self.fc(self.dropout(outputs))\n",
        "      return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "n1Rmk-xwee-u"
      },
      "outputs": [],
      "source": [
        "def function(fecha1,fecha2):\n",
        "    Año_1=int(str(fecha1)[:2])\n",
        "    Mes_1=int(str(fecha1)[-2:])\n",
        "    Año_2=int(str(fecha2)[:2])\n",
        "    Mes_2=int(str(fecha2)[-2:])\n",
        "\n",
        "    dif=12*(Año_2-Año_1)+(Mes_2-Mes_1)\n",
        "    return dif "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funciones Entrenamiento"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlq48WjiW6U"
      },
      "source": [
        "### **Definimos el entrenamiento de la red**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "DV6YLt0oiicW"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, otag=O_TAG_IDX, ft=False):\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "    # Por cada batch del iterador de la época:\n",
        "    for batch in iterator:\n",
        "\n",
        "        # Extraemos el texto y los tags del batch que estamos procesado\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        # print('1',tags)\n",
        "\n",
        "        # Reiniciamos los gradientes calculados en la iteración anterior\n",
        "        optimizer.zero_grad()\n",
        "        #text = [sent len, batch size]\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text)\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        # print(len(predictions))\n",
        "        # print(len(tags))\n",
        "        # print('2',tags)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "        \n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags, o_idx=otag)\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "        # Actualizamos los parámetros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        if ft:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Actualizamos el loss y las métricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNcwKnAz5Hf"
      },
      "source": [
        "### **Definimos la función de evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "id": "WsRuiUuHiicY"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion, otag=O_TAG_IDX):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            # Predecimos\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las métricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags, o_idx=otag)\n",
        "\n",
        "            # Actualizamos el loss y las métricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "id": "Xs-n9Y5yiica"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3MVf5H0A94"
      },
      "source": [
        "\n",
        "### **Entrenamiento de la red**\n",
        "\n",
        "En este cuadro de código ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el número de épocas y luego por cada época, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez. \n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la función `init_weights`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK5lQqpviicf",
        "outputId": "e537d938-03b3-4910-acd1-8f86dfb88f3a"
      },
      "outputs": [],
      "source": [
        "def train_model(model, model_name, train_iterator, valid_iterator, criterion, optimizer, n_epochs, otag=O_TAG_IDX, ft=False):\n",
        "  global device\n",
        "\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "  \n",
        "  #Agregar early stop\n",
        "  best_valid_loss = float('inf')\n",
        "  best_train_loss = float('inf')\n",
        "\n",
        "  arrayTrainLoss = []\n",
        "  arrayValidLoss = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion, otag, ft)\n",
        "\n",
        "    # Evaluar (valid = validación)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion, otag)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    #Nuevo **\n",
        "    arrayTrainLoss.append(train_loss)\n",
        "    arrayValidLoss.append(valid_loss)\n",
        "\n",
        "  #Acá nos aseguramos de que entrene al menos 6 épocas antes de detener el entrenamiento.\n",
        "    if epoch < 7:\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #nuevo\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "      else :\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "\n",
        "  #Early stop, ve que no vaya en aumento, según el avg de las últimas 4 épocas\n",
        "    else:\n",
        "      if train_loss < np.mean(arrayTrainLoss[-4:]) and valid_loss > np.mean(arrayValidLoss[-4:]):\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "        print('Early Stop')\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        best_valid_loss = valid_loss\n",
        "        #nuevo\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "  return model, arrayTrainLoss, arrayValidLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def init_weights(m):\n",
        "#     # Inicializamos los pesos como aleatorios\n",
        "#     for name, param in m.named_parameters():\n",
        "#         nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "#     # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "#     m.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "#     m.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 3,330,548 parámetros entrenables.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.685 | Train f1: 0.44 | Train precision: 0.51 | Train recall: 0.39\n",
            "\t Val. Loss: 0.174 |  Val. f1: 0.90 |  Val. precision: 0.88 | Val. recall: 0.93\n",
            "Epoch: 02 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.138 | Train f1: 0.91 | Train precision: 0.91 | Train recall: 0.92\n",
            "\t Val. Loss: 0.101 |  Val. f1: 0.94 |  Val. precision: 0.91 | Val. recall: 0.97\n",
            "Epoch: 03 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.086 | Train f1: 0.94 | Train precision: 0.93 | Train recall: 0.95\n",
            "\t Val. Loss: 0.075 |  Val. f1: 0.95 |  Val. precision: 0.93 | Val. recall: 0.99\n",
            "Epoch: 04 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.065 | Train f1: 0.96 | Train precision: 0.95 | Train recall: 0.97\n",
            "\t Val. Loss: 0.074 |  Val. f1: 0.96 |  Val. precision: 0.93 | Val. recall: 0.99\n",
            "Epoch: 05 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.053 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.97\n",
            "\t Val. Loss: 0.063 |  Val. f1: 0.96 |  Val. precision: 0.94 | Val. recall: 0.99\n",
            "Epoch: 06 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.045 | Train f1: 0.97 | Train precision: 0.96 | Train recall: 0.98\n",
            "\t Val. Loss: 0.056 |  Val. f1: 0.97 |  Val. precision: 0.94 | Val. recall: 0.99\n",
            "Epoch: 07 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.040 | Train f1: 0.97 | Train precision: 0.97 | Train recall: 0.98\n",
            "\t Val. Loss: 0.054 |  Val. f1: 0.97 |  Val. precision: 0.94 | Val. recall: 0.99\n",
            "Epoch: 08 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.036 | Train f1: 0.98 | Train precision: 0.97 | Train recall: 0.98\n",
            "\t Val. Loss: 0.049 |  Val. f1: 0.97 |  Val. precision: 0.95 | Val. recall: 0.99\n",
            "Epoch: 09 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.033 | Train f1: 0.98 | Train precision: 0.97 | Train recall: 0.98\n",
            "\t Val. Loss: 0.050 |  Val. f1: 0.97 |  Val. precision: 0.95 | Val. recall: 0.99\n",
            "Epoch: 10 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.031 | Train f1: 0.98 | Train precision: 0.97 | Train recall: 0.98\n",
            "\t Val. Loss: 0.044 |  Val. f1: 0.97 |  Val. precision: 0.96 | Val. recall: 0.99\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.501 | Train f1: 0.18 | Train precision: 0.22 | Train recall: 0.17\n",
            "\t Val. Loss: 0.998 |  Val. f1: 0.30 |  Val. precision: 0.83 | Val. recall: 0.19\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.223 | Train f1: 0.22 | Train precision: 0.24 | Train recall: 0.20\n",
            "\t Val. Loss: 0.880 |  Val. f1: 0.19 |  Val. precision: 0.89 | Val. recall: 0.11\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.077 | Train f1: 0.23 | Train precision: 0.25 | Train recall: 0.21\n",
            "\t Val. Loss: 0.843 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.049 | Train f1: 0.24 | Train precision: 0.27 | Train recall: 0.22\n",
            "\t Val. Loss: 0.835 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.035 | Train f1: 0.25 | Train precision: 0.29 | Train recall: 0.22\n",
            "\t Val. Loss: 0.822 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.986 | Train f1: 0.25 | Train precision: 0.29 | Train recall: 0.22\n",
            "\t Val. Loss: 0.823 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.962 | Train f1: 0.25 | Train precision: 0.29 | Train recall: 0.22\n",
            "\t Val. Loss: 0.820 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.980 | Train f1: 0.25 | Train precision: 0.30 | Train recall: 0.22\n",
            "\t Val. Loss: 0.816 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.970 | Train f1: 0.25 | Train precision: 0.30 | Train recall: 0.22\n",
            "\t Val. Loss: 0.814 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.968 | Train f1: 0.26 | Train precision: 0.31 | Train recall: 0.22\n",
            "\t Val. Loss: 0.806 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.944 | Train f1: 0.27 | Train precision: 0.33 | Train recall: 0.23\n",
            "\t Val. Loss: 0.808 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.959 | Train f1: 0.26 | Train precision: 0.32 | Train recall: 0.22\n",
            "\t Val. Loss: 0.809 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.953 | Train f1: 0.26 | Train precision: 0.31 | Train recall: 0.22\n",
            "\t Val. Loss: 0.806 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.938 | Train f1: 0.27 | Train precision: 0.34 | Train recall: 0.23\n",
            "\t Val. Loss: 0.808 |  Val. f1: 0.30 |  Val. precision: 0.80 | Val. recall: 0.19\n",
            "Early Stop\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "N_LAYERS = 3  # número de capas.\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "\n",
        "model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "model_name = 'baseline'\n",
        "model_name_ft = 'baseline_ft'\n",
        "\n",
        "n_epochs = 10\n",
        "n_epochs_ft = 50\n",
        "\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#model.apply(init_weights(model))\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "model, arrayTrainLoss, arrayValidLoss = train_model(model, model_name, train_iterator, valid_iterator, criterion, optimizer, n_epochs)\n",
        "model_ft, arrayTrainLoss_ft, arrayValidLoss_ft = train_model(model, model_name_ft, train_iterator_ft, valid_iterator_ft, criterion, optimizer, n_epochs_ft, otag=O_TAG_IDX, ft=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name_ft)))\n",
        "\n",
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val. Loss: 0.806 |  Val. f1: 0.30 | Val. precision: 0.80 | Val. recall: 0.19\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model_ft, valid_iterator_ft, criterion)\n",
        "# test_loss, test_precision, test_recall, test_f1 = evaluate(model_ft, test_iterator, criterion)\n",
        "\n",
        "print(f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}')\n",
        "# print(f'test_loss: {test_loss:.3f} |  test_f1: {test_f1:.2f} | test_precision: {test_precision:.2f} | test_recall: {test_recall:.2f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 44s\n",
            "\tTrain Loss: 2.468 | Train f1: 0.13 | Train precision: 0.09 | Train recall: 0.23\n",
            "\t Val. Loss: 2.468 |  Val. f1: 0.15 |  Val. precision: 0.10 | Val. recall: 0.26\n",
            "Epoch: 02 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 2.468 | Train f1: 0.13 | Train precision: 0.09 | Train recall: 0.23\n",
            "\t Val. Loss: 2.468 |  Val. f1: 0.15 |  Val. precision: 0.10 | Val. recall: 0.26\n",
            "Epoch: 03 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 2.468 | Train f1: 0.13 | Train precision: 0.09 | Train recall: 0.23\n",
            "\t Val. Loss: 2.468 |  Val. f1: 0.15 |  Val. precision: 0.10 | Val. recall: 0.26\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [445], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m criterion1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[39m=\u001b[39m TAG_PAD_IDX)\n\u001b[1;32m     21\u001b[0m optimizer1 \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m---> 22\u001b[0m model1, arrayTrainLoss1, arrayValidLoss1 \u001b[39m=\u001b[39m train_model(model1, model_name1,train_iterator, valid_iterator, criterion1, optimizer1, n_epochs1)\n",
            "Cell \u001b[0;32mIn [440], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, train_iterator, valid_iterator, criterion, optimizer, n_epochs, otag, ft)\u001b[0m\n\u001b[1;32m     16\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m \u001b[39m# Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# Entrenar\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_loss, train_precision, train_recall, train_f1 \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, otag, ft)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Evaluar (valid = validación)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m valid_loss, valid_precision, valid_recall, valid_f1 \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion, otag)\n",
            "Cell \u001b[0;32mIn [437], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, otag, ft)\u001b[0m\n\u001b[1;32m     35\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, tags)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Calculamos el accuracy\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m precision, recall, f1 \u001b[39m=\u001b[39m calculate_metrics(predictions, tags, o_idx\u001b[39m=\u001b[39;49motag)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Calculamos los gradientes\u001b[39;00m\n\u001b[1;32m     40\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "Cell \u001b[0;32mIn [429], line 26\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(preds, y_true, pad_idx, o_idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_true, y_pred, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m, zero_division\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m, zero_division\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m recall \u001b[39m=\u001b[39m recall_score(y_true, y_pred, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m'\u001b[39;49m, zero_division\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f1\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:571\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    563\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001b[1;32m    564\u001b[0m                                                     average\u001b[39m=\u001b[39maverage,\n\u001b[1;32m    565\u001b[0m                                                     warn_for\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m                                                     scheme\u001b[39m=\u001b[39mscheme,\n\u001b[1;32m    569\u001b[0m                                                     suffix\u001b[39m=\u001b[39msuffix)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 571\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(y_true, y_pred,\n\u001b[1;32m    572\u001b[0m                                                  average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    573\u001b[0m                                                  warn_for\u001b[39m=\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m'\u001b[39;49m,),\n\u001b[1;32m    574\u001b[0m                                                  sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    575\u001b[0m                                                  zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    576\u001b[0m                                                  suffix\u001b[39m=\u001b[39;49msuffix)\n\u001b[1;32m    577\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(true_sum, \u001b[39mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[39m=\u001b[39m _precision_recall_fscore_support(\n\u001b[1;32m    131\u001b[0m     y_true, y_pred,\n\u001b[1;32m    132\u001b[0m     average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m    133\u001b[0m     warn_for\u001b[39m=\u001b[39;49mwarn_for,\n\u001b[1;32m    134\u001b[0m     beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m    135\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    136\u001b[0m     zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m    137\u001b[0m     scheme\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    138\u001b[0m     suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m    139\u001b[0m     extract_tp_actual_correct\u001b[39m=\u001b[39;49mextract_tp_actual_correct\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:124\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(average_options))\n\u001b[1;32m    122\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 124\u001b[0m pred_sum, tp_sum, true_sum \u001b[39m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    127\u001b[0m     tp_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([tp_sum\u001b[39m.\u001b[39msum()])\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:113\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support.<locals>.extract_tp_actual_correct\u001b[0;34m(y_true, y_pred, suffix, *args)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m type_name, start, end \u001b[39min\u001b[39;00m get_entities(y_true, suffix):\n\u001b[1;32m    112\u001b[0m     entities_true[type_name]\u001b[39m.\u001b[39madd((start, end))\n\u001b[0;32m--> 113\u001b[0m \u001b[39mfor\u001b[39;00m type_name, start, end \u001b[39min\u001b[39;00m get_entities(y_pred, suffix):\n\u001b[1;32m    114\u001b[0m     entities_pred[type_name]\u001b[39m.\u001b[39madd((start, end))\n\u001b[1;32m    116\u001b[0m target_names \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(entities_true\u001b[39m.\u001b[39mkeys()) \u001b[39m|\u001b[39m \u001b[39mset\u001b[39m(entities_pred\u001b[39m.\u001b[39mkeys()))\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:193\u001b[0m, in \u001b[0;36mget_entities\u001b[0;34m(seq, suffix)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m end_of_chunk(prev_tag, tag, prev_type, type_):\n\u001b[1;32m    192\u001b[0m     chunks\u001b[39m.\u001b[39mappend((prev_type, begin_offset, i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 193\u001b[0m \u001b[39mif\u001b[39;00m start_of_chunk(prev_tag, tag, prev_type, type_):\n\u001b[1;32m    194\u001b[0m     begin_offset \u001b[39m=\u001b[39m i\n\u001b[1;32m    195\u001b[0m prev_tag \u001b[39m=\u001b[39m tag\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:264\u001b[0m, in \u001b[0;36mstart_of_chunk\u001b[0;34m(prev_tag, tag, prev_type, type_)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m prev_tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    263\u001b[0m     chunk_start \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[39mif\u001b[39;00m prev_tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    265\u001b[0m     chunk_start \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39mif\u001b[39;00m prev_tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m tag \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m'\u001b[39m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Parametros para el modelo 1\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 196\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)\n",
        "embedding_weights = TEXT.vocab.vectors\n",
        "\n",
        "N_LAYERS = 3\n",
        "DROPOUT = 0.15\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "\n",
        "model1 = Modelo1_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name1 = 'Modelo_1'\n",
        "n_epochs1 = 100 #no importa porq hay early stop\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer1 = optim.Adam(model.parameters())\n",
        "model1, arrayTrainLoss1, arrayValidLoss1 = train_model(model1, model_name1,train_iterator, valid_iterator, criterion1, optimizer1, n_epochs1)\n",
        "#model_ft, arrayTrainLoss_ft, arrayValidLoss_ft = train_model(model, model_name_ft, train_iterator_ft, valid_iterator_ft, criterion, optimizer, n_epochs_ft, otag=O_TAG_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model1.load_state_dict(torch.load('{}.pt'.format(model_name1)))\n",
        "\n",
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model1, valid_iterator, criterion)\n",
        "#test_loss, test_precision, test_recall, test_f1 = evaluate(model1, test_iterator, criterion)\n",
        "\n",
        "print(f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}')\n",
        "#print(f'test_loss: {test_loss:.3f} |  test_f1: {test_f1:.2f} | test_precision: {test_precision:.2f} | test_recall: {test_recall:.2f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 196  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.4\n",
        "BIDIRECTIONAL = True\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "\n",
        "model2 = Modelo2_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name2 = 'Modelo_2'\n",
        "n_epochs2 = 30 #no importa porq hay early stop\n",
        "criterion2 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "#optimizer = optim.Adam(model.parameters(),lr=0.3)\n",
        "optimizer2 = optim.SGD(model.parameters(), lr=0.3, momentum=0.9)\n",
        "\n",
        "model2, arrayTrainLoss2, arrayValidLoss2 = train_model(model2, model_name2,train_iterator, valid_iterator,criterion2, optimizer2, n_epochs2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.load_state_dict(torch.load('{}.pt'.format(model_name2)))\n",
        "\n",
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model2, valid_iterator, criterion)\n",
        "#test_loss, test_precision, test_recall, test_f1 = evaluate(model2, test_iterator, criterion)\n",
        "\n",
        "print(f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}')\n",
        "#print(f'test_loss: {test_loss:.3f} |  test_f1: {test_f1:.2f} | test_precision: {test_precision:.2f} | test_recall: {test_recall:.2f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.3\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model3 = GruNet(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name3 = 'Gru_Model'  # nombre que tendrá el modelo guardado...\n",
        "n_epochs3 = 10\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "\n",
        "criterion3 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer3 = optim.Adam(model3.parameters())\n",
        "model3, arrayTrainLoss3, arrayValidLoss3 = train_model(model3, model_name3, criterion3, optimizer3, n_epochs3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3.load_state_dict(torch.load('{}.pt'.format(model_name3)))\n",
        "\n",
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model3, valid_iterator, criterion)\n",
        "#test_loss, test_precision, test_recall, test_f1 = evaluate(model3, test_iterator, criterion)\n",
        "\n",
        "print(f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}')\n",
        "#print(f'test_loss: {test_loss:.3f} |  test_f1: {test_f1:.2f} | test_precision: {test_precision:.2f} | test_recall: {test_recall:.2f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "## **Predecir datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RBs3UU4wLk3"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "                predictions.append(['EOS', 'EOS'])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcmEqmemHqJD",
        "outputId": "be1188b6-dd94-4cf9-8f93-670f900c2f7d"
      },
      "outputs": [],
      "source": [
        "# predictions = predict_labels(model_ft, test_loader, criterion)\n",
        "predictions = predict_labels(model_ft, test_iterator_ft, criterion)\n",
        "# predictions_m3 = predict_labels(model3, test_iterator, criterion3)\n",
        "\n",
        "# predictions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### **Generar el archivo**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPfZkjJGkWyq"
      },
      "outputs": [],
      "source": [
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for i, (word, tag) in enumerate(predictions[:-1]):\n",
        "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
        "    else: \n",
        "      if i == len(predictions[:-1])-1:\n",
        "        f.write(word + ' ' + tag)\n",
        "      else: f.write(word + ' ' + tag + '\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
