{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de tokens con HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../datos/procesamiento')\n",
    "from corpus import Corpus\n",
    "from etiquetado_entidades import codigo_hfl, split_rule, process_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_db = pd.read_csv('../datos/DATA_HLF_MDS_2.csv',sep=',')\n",
    "\n",
    "code_db = pd.read_excel('../datos/PRINCIPIOS_ACTIVOS_MDS.xlsx')\n",
    "HLF = code_db.loc[:,['PRINCIPIO_ACTIVO','CODIGO_HLF']]\n",
    "HLF_df = codigo_hfl(HLF)\n",
    "\n",
    "df = main_db.join(HLF_df.set_index('CODIGO_MEDICAMENTO'), on='CODIGO_MEDICAMENTO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar principios activos, forma farma y juntar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA DETECTAR LA POSICION DE ENTIDADES TIPO PRINCIPIO ACTIVO, FORMA FARMACO SE COMPARARAN LOS ELEMENTOS DEL CORPUS CON LAS LISTAS CORRESPONDIENTES.\n",
    "PA = np.unique(split_rule(df['PRINCIPIO_ACTIVO'].dropna().unique()))\n",
    "FF = np.unique(split_rule(df['FORMA_FARMA'].dropna().unique()))\n",
    "\n",
    "rows = (df['PRES_DENOMINACION'] + ' ' + df['RESUMEN']).dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar procesamiento de datos de Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    row = rows[i].split()\n",
    "    tagged_seq = process_column(row,PA,FF)\n",
    "\n",
    "    corpus.append(tagged_seq)\n",
    "\n",
    "    if i > 100:\n",
    "        # solo testeando :)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cargando el corpus como dataset de HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dict = {'O': 0,\n",
    "            'B-ACTVPRNCP': 1,\n",
    "            'I-ACTVPRNCP': 2,\n",
    "            'B-ADMIN': 3,\n",
    "            'I-ADMIN': 4,\n",
    "            'B-PERIODICITY': 5,\n",
    "            'I-PERIODICITY': 6,\n",
    "            'B-DURATION': 7,\n",
    "            'I-DURATION': 8\n",
    "            }\n",
    "\n",
    "corpus.entidades = ner_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_dataset = corpus.to_HF_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryTable\n",
       "id: int64\n",
       "tokens: list<item: string>\n",
       "  child 0, item: string\n",
       "ner_tags: list<item: int64>\n",
       "  child 0, item: int64\n",
       "----\n",
       "id: [[0,1,2,3,4,...,97,98,99,100,101]]\n",
       "tokens: [[[\"PARACETAMOL\",\"500\",\"MG\",\"COMPRIMIDO\",\"1\",...,\"6\",\"horas\",\"durante\",\"3\",\"dias\"],[\"KETOROLACO\",\"10\",\"MG\",\"COMPRIMIDO\",\"1\",...,\"8\",\"horas\",\"durante\",\"3\",\"dias\"],...,[\"KETOPROFENO\",\"50\",\"MG\",\"CÁPSULA\",\"1\",...,\"ORAL\",\"tres\",\"veces\",\"al\",\"día\"],[\"DICLOFENACO\",\"75\",\"MG/3\",\"ML\",\"SOLUCIÓN\",...,\"1\",\"UNIDAD\",\"INTRAMUSCULAR\",\"dosis\",\"simple\"]]]\n",
       "ner_tags: [[[1,0,0,3,0,...,6,6,7,8,8],[1,0,0,3,0,...,6,6,7,8,8],...,[1,0,0,3,0,...,3,0,0,0,0],[1,0,0,0,1,...,0,0,0,0,0]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ACTVPRNCP',\n",
       " 'I-ACTVPRNCP',\n",
       " 'B-ADMIN',\n",
       " 'I-ADMIN',\n",
       " 'B-PERIODICITY',\n",
       " 'I-PERIODICITY',\n",
       " 'B-DURATION',\n",
       " 'I-DURATION']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_dataset.features[f\"ner_tags\"].feature.names = [key for key in ner_dict.keys()]\n",
    "HF_dataset.features[f\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 21\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_dataset = HF_dataset.train_test_split(test_size=0.2,seed=0)\n",
    "HF_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos un modelo basado en Transformers de HuggingFace\n",
    "\n",
    "Nuestro modelo será: plncmm/bert-clinical-scratch-wl-es. Ha sido fine-tuneado con texto médico (aunque probablemente no con prescripciones)\n",
    "\n",
    "[Fuente de esta sección](https://huggingface.co/docs/transformers/tasks/token_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"plncmm/bert-clinical-scratch-wl-es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el tokenizador para codificar nuestro input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'meta',\n",
       " '##mi',\n",
       " '##zo',\n",
       " '##l',\n",
       " 'só',\n",
       " '##dico',\n",
       " '1',\n",
       " 'g',\n",
       " '/',\n",
       " '2',\n",
       " 'ml',\n",
       " 'solución',\n",
       " 'inyecta',\n",
       " '##ble',\n",
       " 'amp',\n",
       " '##olla',\n",
       " '2',\n",
       " 'ml',\n",
       " '4',\n",
       " 'unidad',\n",
       " 'paren',\n",
       " '##tera',\n",
       " '##l',\n",
       " 'diaria',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = HF_dataset[\"train\"][0]\n",
    "\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos corregir el _mismatch_ entre input tokenizado y la lista de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b866ffc0894594b779ac652b016adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65b4f9686514b29abd41183ed4dea63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = HF_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': InMemoryTable\n",
       " id: int64\n",
       " tokens: list<item: string>\n",
       "   child 0, item: string\n",
       " ner_tags: list<item: int64>\n",
       "   child 0, item: int64\n",
       " input_ids: list<item: int32>\n",
       "   child 0, item: int32\n",
       " token_type_ids: list<item: int8>\n",
       "   child 0, item: int8\n",
       " attention_mask: list<item: int8>\n",
       "   child 0, item: int8\n",
       " labels: list<item: int64>\n",
       "   child 0, item: int64\n",
       " ----\n",
       " id: [[23,22,19,101,92,...,41,56,33,79,95]]\n",
       " tokens: [[[\"METAMIZOL\",\"SÓDICO\",\"1\",\"G/2\",\"ML\",...,\"ML\",\"4\",\"UNIDAD\",\"PARENTERAL\",\"diaria\"],[\"CEFTRIAXONA\",\"1\",\"G\",\"POLVO\",\"LIOFILIZADO\",...,\"24\",\"horas\",\"durante\",\"21\",\"dias\"],...,[\"ISOSORBIDE\",\"DINITRATO\",\"10\",\"MG\",\"COMPRIMIDO\",...,\"COMPRIMIDO\",\"ORAL\",\"cada\",\"8\",\"horas\"],[\"SULPIRIDA\",\"50\",\"MG\",\"ORAL\",\"1\",...,\"DURA\",\"ORAL\",\"cada\",\"8\",\"horas\"]]]\n",
       " ner_tags: [[[1,2,0,0,0,...,0,0,0,0,0],[1,0,0,3,4,...,6,6,7,8,8],...,[1,2,0,0,3,...,3,4,5,6,6],[1,0,0,3,0,...,4,3,5,6,6]]]\n",
       " input_ids: [[[4,6265,1446,1600,30962,...,15843,2432,30962,15359,5],[4,1651,4714,3886,14008,...,2596,1672,2744,12873,5],...,[4,15023,13394,1177,1114,...,12791,1748,997,2596,5],[4,9551,5397,1238,3092,...,12791,1748,997,2596,5]]]\n",
       " token_type_ids: [[[0,0,0,0,0,...,0,0,0,0,0],[0,0,0,0,0,...,0,0,0,0,0],...,[0,0,0,0,0,...,0,0,0,0,0],[0,0,0,0,0,...,0,0,0,0,0]]]\n",
       " attention_mask: [[[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1],...,[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1]]]\n",
       " labels: [[[-100,1,-100,-100,-100,...,0,-100,-100,0,-100],[-100,1,-100,-100,-100,...,6,7,8,8,-100],...,[-100,1,-100,-100,-100,...,4,5,6,6,-100],[-100,1,-100,-100,0,...,3,5,6,6,-100]]],\n",
       " 'test': InMemoryTable\n",
       " id: int64\n",
       " tokens: list<item: string>\n",
       "   child 0, item: string\n",
       " ner_tags: list<item: int64>\n",
       "   child 0, item: int64\n",
       " input_ids: list<item: int32>\n",
       "   child 0, item: int32\n",
       " token_type_ids: list<item: int8>\n",
       "   child 0, item: int8\n",
       " attention_mask: list<item: int8>\n",
       "   child 0, item: int8\n",
       " labels: list<item: int64>\n",
       "   child 0, item: int64\n",
       " ----\n",
       " id: [[84,37,20,5,85,...,99,8,87,9,34]]\n",
       " tokens: [[[\"RANITIDINA\",\"50\",\"MG/2\",\"ML\",\"SOLUCIÓN\",...,\"MG\",\"INTRAVENOSA\",\"cada\",\"8\",\"horas\"],[\"GLUCOSA\",\"5\",\"%\",\"SOLUCIÓN\",\"INYECTABLE\",...,\"ML\",\"1\",\"UNIDAD\",\"PARENTERAL\",\"diaria\"],...,[\"FENOTEROL\",\"BROMHIDRATO\",\"0,5\",\"MG/ML\",\"+\",...,\"6\",\"horas\",\"durante\",\"3\",\"dias\"],[\"HEPARINA\",\"SÓDICA\",\"25.000\",\"U.I./5\",\"ML\",...,\"ML\",\"1\",\"UNIDAD\",\"PARENTERAL\",\"diaria\"]]]\n",
       " ner_tags: [[[1,0,0,0,1,...,0,0,5,6,6],[1,0,0,1,2,...,0,0,0,0,0],...,[1,2,0,0,1,...,6,6,7,8,8],[1,2,0,0,0,...,0,0,0,0,0]]]\n",
       " input_ids: [[[4,4008,11086,11389,30956,...,1976,1748,997,2596,5],[4,27921,1413,991,4667,...,15843,2432,30962,15359,5],...,[4,5536,8413,1213,30962,...,2596,1672,1306,12873,5],[4,25613,18642,9006,3514,...,15843,2432,30962,15359,5]]]\n",
       " token_type_ids: [[[0,0,0,0,0,...,0,0,0,0,0],[0,0,0,0,0,...,0,0,0,0,0],...,[0,0,0,0,0,...,0,0,0,0,0],[0,0,0,0,0,...,0,0,0,0,0]]]\n",
       " attention_mask: [[[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1],...,[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1]]]\n",
       " labels: [[[-100,1,-100,-100,-100,...,-100,5,6,6,-100],[-100,1,0,0,1,...,0,-100,-100,0,-100],...,[-100,1,-100,-100,-100,...,6,7,8,8,-100],[-100,1,-100,2,-100,...,0,-100,-100,0,-100]]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at plncmm/bert-clinical-scratch-wl-es were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at plncmm/bert-clinical-scratch-wl-es and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL, num_labels=len(ner_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 3,\n",
    "    weight_decay = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = tokenized_data[\"train\"],\n",
    "    eval_dataset = tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633867f6f1684d578beff22699f42799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb099c4a53d643428baaed050af71a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7249085307121277, 'eval_runtime': 0.1981, 'eval_samples_per_second': 106.016, 'eval_steps_per_second': 10.097, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26db7065ed64326a844197564ba3396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.562258780002594, 'eval_runtime': 0.1992, 'eval_samples_per_second': 105.432, 'eval_steps_per_second': 10.041, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e87c5d88484da580c961a8d024403e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48975545167922974, 'eval_runtime': 0.207, 'eval_samples_per_second': 101.441, 'eval_steps_per_second': 9.661, 'epoch': 3.0}\n",
      "{'train_runtime': 13.4633, 'train_samples_per_second': 18.049, 'train_steps_per_second': 1.337, 'train_loss': 0.7343078189425998, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.7343078189425998, metrics={'train_runtime': 13.4633, 'train_samples_per_second': 18.049, 'train_steps_per_second': 1.337, 'train_loss': 0.7343078189425998, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('entidades_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60cab8a6eccdbb291cd8546425070b6bbfbad3cae25f59923f3919ec9d23e6db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
