{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH4HqnCjSWs-"
      },
      "source": [
        "**Corpus de la Lista de espera**\n",
        "\n",
        "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber más sobre cómo fueron generados los datos pueden revisar el paper publicado hace unos meses atrás en el workshop de EMNLP, una de las conferencias más importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
        "\n",
        "Este corpus Chileno está constituido originalmente por 7 tipos de entidades pero por simplicidad en esta competencia trabajarán con las siguientes:\n",
        "\n",
        "- **Disease**\n",
        "- **Body_Part**\n",
        "- **Medication** \n",
        "- **Procedures** \n",
        "- **Family_Member**\n",
        "\n",
        "Si quieren obtener más información sobre estas entidades pueden consultar la [guía de anotación](https://plncmm.github.io/annodoc/). Además, mencionar que este corpus está restringido bajo una licencia que permite solamente su uso académico, así que no puede ser compartido más allá de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este último es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los términos y condiciones de la competencia están de acuerdo con los puntos descritos anteriormente.\n",
        "\n",
        "\n",
        "**Formato ConLL**\n",
        "\n",
        "Los archivos que serán entregados a ustedes vienen en un formato estándar utilizado en NER, llamado ConLL. No es más que un archivo de texto, que cumple las siguientes propiedades.\n",
        "\n",
        "- Un salto de linea corresponde a la separación entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, más conocidos como batches.\n",
        "\n",
        "- La primera columna del archivo contiene todos los tokens de la partición.\n",
        "\n",
        "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
        "\n",
        "- Los tipos de entidades siguen un formato clásico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token está asociado a la categoría O (Outside) significa que no pertenece a ninguna entidad.\n",
        "\n",
        "Aquí va un ejemplo:\n",
        "\n",
        "```\n",
        "PACIENTE O\n",
        "PRESENTA O\n",
        "FRACTURA B-Disease\n",
        "CORONARIA I-Disease\n",
        "COMPLICADA I-Disease\n",
        "EN O\n",
        "PIE B-Body_Part\n",
        "IZQUIERDO I-Body_Part\n",
        ". O\n",
        "SE O\n",
        "REALIZA O\n",
        "INSTRUMENTACION B-Procedure\n",
        "INTRACONDUCTO I-Procedure\n",
        ". O\n",
        "```\n",
        "\n",
        "Según nuestra definición tenemos las siguientes tres entidades (enumerando desde 0): \n",
        "\n",
        "- $(2, 4, Disease)$\n",
        "- $(6, 7, Body Part)$\n",
        "- $(11, 12, Procedure)$\n",
        "\n",
        "\n",
        "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la competencia:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "# **Introducción**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVL0-01AUOzL"
      },
      "source": [
        "En el presente trabajo muestra la clasificación de la palabras a traves de Named Entity Recognition (NER). NER consiste en intentar extraer entindades en el traxto a traves de etiquetas pre definidas, como pueden ser nombres de persona, organizaciones, fechas, lugares, entre otros.\n",
        "\n",
        "  Específicamente, en este trabajo se trata de realizar el reconocimiento de entidades en un dataset clínico que corresponde a la lista de espera no GES en Chile. La idea es clasificar las palabras en alguna de las siguientes 6 etiquetas: `Disease`, para las enfermedades; `Body_part`, para alguna parte del cuerpo, incluye órganos; `Medication`, para cualquier tipo de medicamento que sea nombrado; `Procedures`, hace referencia a todos los tipos de procedimientos que puede someterse un paciente; `Family_Member`, para familiares del paciente y `O`, para cualquier otra palabra que no quepa dentro de alguna de las categorías anteriores.\n",
        "\n",
        "  Para su realización, empleamos 3 modelos distintos en los que se utilizan distintas arquitecturas de redes neuronales, como lo son las LSTM y GRU. Además se utilizó una biblioteca de embeddings pre entrenados como tipo Glove y Fast Text, para aumetar el accuracy del sistema.\n",
        "\n",
        "  A continuación se encuentra n las descripciones de los modelos, las métricas de evaluación utilizadas. El diseño experimental, que explica el funcionamiento de los modelos, luego viene la implementación de estos y sus resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  **Carga de datos y Preprocesamiento**\n",
        "\n",
        "Para cargar los datos y preprocesarlos usaremos la librería [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librería tuvo cambios radicales, quedando las funcionalidades pasadas en un nuevo paquete llamado legacy. Esto ya que si quieren usar más funciones de la librería entonces vean los cambios en la documentación.\n",
        "\n",
        "En particular usaremos su módulo `data`, el cual según su documentación original provee: \n",
        "\n",
        "    - Ability to describe declaratively how to load a custom NLP dataset that's in a \"normal\" format\n",
        "    - Ability to define a preprocessing pipeline\n",
        "    - Batching, padding, and numericalizing (including building a vocabulary object)\n",
        "    - Wrapper for dataset splits (train, validation, test)\n",
        "\n",
        "\n",
        "El proceso será el siguiente: \n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
        "3. Cargar los datasets.\n",
        "4. Crear el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27csY87GaSFO",
        "outputId": "83f602c5-c7e0-477d-d8e3-68498f307ae5",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Instalamos torchtext que nos facilitará la vida en el pre-procesamiento del formato ConLL.\n",
        "# !pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gzip\n",
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "\n",
        "from operator import attrgetter\n",
        "from torchtext import vocab, datasets ,data\n",
        "#from torchtext.legacy import data #, datasets\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ng7wRGEyawjM"
      },
      "outputs": [],
      "source": [
        "# Garantizar reproducibilidad de los experimentos\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BehSou6rCvwg"
      },
      "source": [
        "#### **Obtener datos**\n",
        "\n",
        "Descargamos los datos de entrenamiento, validación y prueba en nuestro directorio de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbT0g_kC18Jb",
        "outputId": "0c46702a-a00a-4140-d763-3bcb49cd76a6"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "\n",
        "# !wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n",
        "# !wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
        "# !wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMud7YGMBZvg"
      },
      "source": [
        "####  **Fields**\n",
        "\n",
        "Un `field`:\n",
        "\n",
        "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
        "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
        "* Contiene otros parámetros relacionados con la forma en que se debe numericalizar un tipo de datos, como un método de tokenización y el tipo de Tensor que se debe producir.\n",
        "\n",
        "\n",
        "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
        "\n",
        "\n",
        "```\n",
        "El O\n",
        "paciente O\n",
        "padece O\n",
        "de O\n",
        "cancer B-Disease\n",
        "de I-Disease\n",
        "colon I-Disease\n",
        ". O\n",
        "```\n",
        "\n",
        "Cada linea contiene un token y el tipo de entidad asociado en el formato IOB2 ya explicado. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
        "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y las etiquetas o categorías (`NER_TAGS`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "3DcM_IjgCdzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(('text', <torchtext.data.field.Field object at 0x7f98405708e0>), ('nertags', <torchtext.data.field.Field object at 0x7f98405708b0>))\n"
          ]
        }
      ],
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))\n",
        "\n",
        "print(fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  **SequenceTaggingDataset**\n",
        "\n",
        "`SequenceTaggingDataset` es una clase de torchtext diseñada para contener datasets de sequence labeling. Los ejemplos que se guarden en una instancia de estos serán arreglos de palabras asociados con sus respectivos tags.\n",
        "\n",
        "Por ejemplo, para Part-of-speech tagging:\n",
        "\n",
        "[I, love, PyTorch, .] estará asociado con [PRON, VERB, PROPN, PUNCT]\n",
        "\n",
        "\n",
        "La idea es que usando los fields que definimos antes, le indiquemos a la clase cómo cargar los datasets de prueba, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "HsHdGml62J21"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"corpus_recetas_train.txt\",\n",
        "    validation=\"corpus_recetas_val.txt\",\n",
        "    test=\"corpus_recetas_test.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"utf-8\",\n",
        "    separator=\" \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# valid_data = train_data[int(len(train_data)*0.7):int(len(train_data)*0.8)]\n",
        "# test_data = train_data[int(len(train_data)*0.8):len(train_data)]\n",
        "# train_data = train_data[0:int(len(train_data)*0.7)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu7q3HCliia5",
        "outputId": "ed55cb56-d9d8-4a56-a63d-db5bd222c448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 500\n",
            "Número de ejemplos de validación: 250\n",
            "Número de ejemplos de test (competencia): 250\n"
          ]
        }
      ],
      "source": [
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test (competencia): {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDRnhXAdFGL-"
      },
      "source": [
        "Visualizemos un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T023Ld4RaSF4",
        "outputId": "f660c744-ebec-4138-e573-e04526d27c7b",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('TRAMADOL', 'B-ACTVPRNCP'),\n",
              " ('100', 'O'),\n",
              " ('MG/ML', 'O'),\n",
              " ('SOLUCIÓN', 'B-ADMIN'),\n",
              " ('ORAL', 'I-ADMIN'),\n",
              " ('FRASCO', 'O'),\n",
              " ('10', 'O'),\n",
              " ('ML', 'O'),\n",
              " ('5', 'O'),\n",
              " ('GOTAS', 'B-ADMIN'),\n",
              " ('ORAL', 'I-ADMIN'),\n",
              " ('cada', 'B-PERIODICITY'),\n",
              " ('8', 'I-PERIODICITY'),\n",
              " ('horas', 'I-PERIODICITY'),\n",
              " ('durante', 'B-DURATION'),\n",
              " ('7', 'I-DURATION'),\n",
              " ('dias', 'I-DURATION')]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### **Construir los vocabularios para el texto y las etiquetas**\n",
        "\n",
        "Los vocabularios son los objetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields. El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PBhp7WICiibL"
      },
      "outputs": [],
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4OgUKM_iibO",
        "outputId": "694db208-63ad-4026-f035-47d37bd80574",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 683\n",
            "Tokens únicos en NER_TAGS: 10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4FeyL9nFnId",
        "outputId": "a486ba2a-d653-4839-ba12-ff1a1184f372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " 'O',\n",
              " 'B-ADMIN',\n",
              " 'B-ACTVPRNCP',\n",
              " 'I-ADMIN',\n",
              " 'I-PERIODICITY',\n",
              " 'I-DURATION',\n",
              " 'B-PERIODICITY',\n",
              " 'I-ACTVPRNCP',\n",
              " 'B-DURATION']"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "NER_TAGS.vocab.itos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYQDoUqSHFKj"
      },
      "source": [
        "Observen que ademas de los tags NER, tenemos \\<pad\\>, el cual es generado por el dataloader para cumplir con el padding de cada oración.\n",
        "\n",
        "Veamos ahora los tokens mas frecuentes y especiales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5eSLm4diibR",
        "outputId": "7df5c5c1-b01a-48dd-fa38-11dee22df1a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ML', 352),\n",
              " ('MG', 332),\n",
              " ('ORAL', 284),\n",
              " ('cada', 279),\n",
              " ('COMPRIMIDO', 273),\n",
              " ('horas', 267),\n",
              " ('1', 235),\n",
              " ('SOLUCIÓN', 213),\n",
              " ('INYECTABLE', 210),\n",
              " ('AMPOLLA', 197)]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokens mas frecuentes (Será necesario usar stopwords, eliminar símbolos o nos entregan información (?) )\n",
        "TEXT.vocab.freqs.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "WDyNLMPz9duD"
      },
      "outputs": [],
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrYvF3X0sjWL"
      },
      "source": [
        "#### **Frecuencia de los Tags**\n",
        "\n",
        "Visualizemos rápidamente las cantidades y frecuencias de cada tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuXOsbJUiibh",
        "outputId": "90842a04-d80b-44d1-d0cc-a58d9436ebe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t4122\t54.4%\n",
            "B-ADMIN\t789\t10.4%\n",
            "B-ACTVPRNCP\t622\t 8.2%\n",
            "I-ADMIN\t602\t 7.9%\n",
            "I-PERIODICITY\t554\t 7.3%\n",
            "I-DURATION\t292\t 3.9%\n",
            "B-PERIODICITY\t277\t 3.7%\n",
            "I-ACTVPRNCP\t177\t 2.3%\n",
            "B-DURATION\t146\t 1.9%\n"
          ]
        }
      ],
      "source": [
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### **Configuramos pytorch y dividimos los datos.**\n",
        "\n",
        "Importante: si tienes problemas con la ram de la gpu, disminuye el tamaño de los batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB7cwLWpaSGs",
        "outputId": "c48241fb-7105-4b4a-e58f-b85efc2443d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32 #16  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test. Si van a hacer algún sort no puede ser sobre\n",
        "# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n",
        "# debe conservar el orden original para ser comparado con los golden_labels. \n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B21E1eAFId16"
      },
      "source": [
        "#### **Métricas de evaluación**\n",
        "\n",
        "Además, definiremos las métricas que serán usadas tanto para la competencia como para evaluar el modelo: `precision`, `recall` y `micro f1-score`.\n",
        "**Importante**: Noten que la evaluación solo se hace para las Named Entities (sin contar 'O'), toda esta funcionalidad nos la entrega la librería seqeval, pueden revisar más documentación aquí: https://github.com/chakki-works/seqeval. No utilicen el código entregado por sklearn para calcular las métricas ya que esta lo hace a nivel de token y no a nivel de entidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9mUOOLEWiicU"
      },
      "outputs": [],
      "source": [
        "# Definimos las métricas\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # filtramos <pad> para calcular los scores.\n",
        "    mask = [(y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
        "    y_true = y_true.to('cpu').numpy()\n",
        "    y_pred = [[NER_TAGS.vocab.itos[v] for v in y_pred]]\n",
        "    y_true = [[NER_TAGS.vocab.itos[v] for v in y_true]]\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
        "    precision = precision_score(y_true, y_pred, mode='strict')\n",
        "    recall = recall_score(y_true, y_pred, mode='strict')\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### **Modelo Baseline**\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrá una capa de embedding, unas cuantas LSTM y una capa de salida y usará dropout en el entrenamiento.\n",
        "\n",
        "Este constará de los siguientes pasos: \n",
        "\n",
        "1. Definir la clase que contendrá la red.\n",
        "2. Definir los hiperparámetros e inicializar la red. \n",
        "3. Definir el número de épocas de entrenamiento\n",
        "4. Definir la función de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "rMPL08XqaSG3"
      },
      "outputs": [],
      "source": [
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx,\n",
        "                                      )\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### **Hiperparámetros de la red**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "EHdi3QdOaSG8"
      },
      "outputs": [],
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 3  # número de capas.\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jlF1DhJeaSHA"
      },
      "outputs": [],
      "source": [
        "baseline_n_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3u4imJGaSHE"
      },
      "source": [
        "#### Definimos la función de loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "6G_4k99_aSHG"
      },
      "outputs": [],
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n",
        "\n",
        "En estas secciones pueden implementar nuevas redes al modificar los hiperparámetros, la cantidad de épocas de entrenamiento, el tamaño de los batches, loss, optimizador, etc... como también definir nuevas arquitecturas de red (mediante la creación de clases nuevas)\n",
        "\n",
        "\n",
        "Al final de estas, hay 4 variables, las cuales deben setear con los modelos, épocas de entrenamiento, loss y optimizador que deseen probar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "gkKeMSG5-X2u"
      },
      "outputs": [],
      "source": [
        "# Caergamos Glove o fast text\n",
        "FASTTEXT_FILE = \"glove300d.vec\"\n",
        "# Se descargan vectores glove o fasttext del github del dcc\n",
        "# https://github.com/dccuchile/spanish-word-embeddings\n",
        "\n",
        "if not os.path.exists(FASTTEXT_FILE):\n",
        "    print(f\"Descargando {FASTTEXT_FILE}\")\n",
        "    url = \"http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\"\n",
        "    #url = \"https://s06.imfd.cl/04/fasttext-sbwc.vec.gz\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    try:\n",
        "        with gzip.open(response.raw, \"rb\") as f_in:\n",
        "            with open(FASTTEXT_FILE, \"wb\") as f_out:\n",
        "                # Funcion para copiar de un file-like object a otro\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    except Exception as e:\n",
        "        os.remove(FASTTEXT_FILE)\n",
        "        raise e\n",
        "\n",
        " #dimensión es de 300 y tiene 855,380 vectores pre-entrenados. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "WbUcstoE-dae"
      },
      "outputs": [],
      "source": [
        "embeddings = vocab.Vectors(FASTTEXT_FILE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "jv--Fgg4-eD1"
      },
      "outputs": [],
      "source": [
        "TEXT.vocab.set_vectors(*attrgetter(\"stoi\", \"vectors\", \"dim\")(embeddings))\n",
        "#se asocian los tokens de text a los vectores del embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXxoZaDa-hB1",
        "outputId": "46a33258-fd90-4351-a805-3cb01d3a4d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "kqjY7bMr-lAd"
      },
      "outputs": [],
      "source": [
        "class Modelo1_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_weights.clone(), freeze = False)\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "WfA_GJXS-od0"
      },
      "outputs": [],
      "source": [
        "#Parametros para el modelo 1\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 196\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)\n",
        "embedding_weights = TEXT.vocab.vectors\n",
        "\n",
        "N_LAYERS = 3\n",
        "DROPOUT = 0.15\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "2uykb0WH-rCd"
      },
      "outputs": [],
      "source": [
        "modelo_1 = Modelo1_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name_1 = 'Modelo_1'\n",
        "n_epochs_1 = 100 #no importa porq hay early stop\n",
        "criterion_1 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exkwfNUf_NKX",
        "outputId": "15fafaa8-e1c2-44b0-a9eb-730167a9500e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 62 # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test. Si van a hacer algún sort no puede ser sobre\n",
        "# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n",
        "# debe conservar el orden original para ser comparado con los golden_labels. \n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "DRFzYrLPAC4y"
      },
      "outputs": [],
      "source": [
        "class Modelo2_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_weights.clone(), freeze = False)\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "        #self.relu = nn.ReLU()\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "tue0pF8nAKf9"
      },
      "outputs": [],
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 196  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.4\n",
        "BIDIRECTIONAL = True\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "enH5KULuAU2P"
      },
      "outputs": [],
      "source": [
        "modelo_2 = Modelo2_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name_2 = 'Modelo_2'\n",
        "n_epochs_2 = 30 #no importa porq hay early stop\n",
        "criterion_2 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "_w0CFjA8aSHU"
      },
      "outputs": [],
      "source": [
        "# Para crear la red debemos heredar desde nn.Module\n",
        "class GruNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "      super().__init__()\n",
        "\n",
        "      # Capa de embedding\n",
        "      self.embedding = nn.Embedding(input_dim,\n",
        "                                    embedding_dim,\n",
        "                                    padding_idx=pad_idx,\n",
        "                                    )\n",
        "      \n",
        "      \n",
        "      # Capa GRU\n",
        "      self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout = dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n",
        "\n",
        "      # Capa de salida\n",
        "      self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "      #self.relu = nn.ReLU()\n",
        "\n",
        "      # Dropout\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Definimos las operaciones de las capas sobre el input en el forward.\n",
        "    def forward(self, text): \n",
        "\n",
        "      embedded = self.embedding(text)\n",
        "\n",
        "      outputs, hidden = self.gru(embedded)\n",
        "\n",
        "      predictions = self.fc(self.dropout(outputs))\n",
        "\n",
        "\n",
        "      return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Py5GF1OmqTcM"
      },
      "outputs": [],
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.3\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "modelo_3 = GruNet(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_name_3 = 'Gru_Model'  # nombre que tendrá el modelo guardado...\n",
        "\n",
        "n_epochs_3 = 10\n",
        "\n",
        "\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "criterion_3 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGdirx7aSHZ"
      },
      "source": [
        "------\n",
        "### **Entrenamos y evaluamos**\n",
        "\n",
        "\n",
        "**Importante** : Fijen el modelo, el número de épocas de entrenamiento, la loss y el optimizador que usarán para entrenar y evaluar en las siguientes variables!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "r8YlGnjxaSHZ"
      },
      "outputs": [],
      "source": [
        "model = baseline_model\n",
        "model_name = baseline_model_name\n",
        "criterion = baseline_criterion\n",
        "n_epochs = baseline_n_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "XlTESppBAe8U"
      },
      "outputs": [],
      "source": [
        "# model = modelo_1\n",
        "# model_name = model_name_1\n",
        "# criterion = criterion_1\n",
        "# n_epochs = n_epochs_1\n",
        "\n",
        "# # Optimizador\n",
        "# optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "htWsmsRdBNAj"
      },
      "outputs": [],
      "source": [
        "# model = modelo_2\n",
        "# model_name = model_name_2\n",
        "# criterion = criterion_2\n",
        "# n_epochs = n_epochs_2\n",
        "\n",
        "# # Optimizador\n",
        "# #optimizer = optim.Adam(model.parameters(),lr=0.3)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.3, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qPkD8Ps3qhmL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# model = modelo_3\n",
        "# model_name = model_name_3\n",
        "# criterion = criterion_3\n",
        "# n_epochs = n_epochs_3\n",
        "\n",
        "# # Optimizador\n",
        "# optimizer = optim.Adam(model.parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ykWz-bSYc9v0",
        "outputId": "14d3fe1c-68a5-4fed-88f1-f1d4f2f2c8e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'12'"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a ='123'\n",
        "a[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "n1Rmk-xwee-u"
      },
      "outputs": [],
      "source": [
        "def function(fecha1,fecha2):\n",
        "    Año_1=int(str(fecha1)[:2])\n",
        "    Mes_1=int(str(fecha1)[-2:])\n",
        "    Año_2=int(str(fecha2)[:2])\n",
        "    Mes_2=int(str(fecha2)[-2:])\n",
        "\n",
        "    dif=12*(Año_2-Año_1)+(Mes_2-Mes_1)\n",
        "    return dif "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_lXic2aSHd"
      },
      "source": [
        "\n",
        "\n",
        "#### **Inicializamos la red**\n",
        "\n",
        "Iniciamos los pesos de la red de forma aleatoria (Usando una distribución normal).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-G_NWFcaSHe",
        "outputId": "207adfd0-f8d3-4b7e-cf94-4dcf27fddab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NER_RNN(\n",
              "  (embedding): Embedding(683, 300, padding_idx=1)\n",
              "  (lstm): LSTM(300, 256, num_layers=3, dropout=0.5)\n",
              "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "        \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjWDX2CJaSHh",
        "outputId": "110536a6-4fe8-46dc-9ff4-81bcb6880b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 1,831,534 parámetros entrenables.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZvHtwpaSHq"
      },
      "source": [
        "#### **Definimos el optimizador**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "AH6o8_cTaSHq"
      },
      "outputs": [],
      "source": [
        "# Optimizador\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz39wa78wGYR"
      },
      "source": [
        "#### **Enviamos el modelo a cuda**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "dqr0AJ6_iicR"
      },
      "outputs": [],
      "source": [
        "# Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlq48WjiW6U"
      },
      "source": [
        "#### **Definimos el entrenamiento de la red**\n",
        "\n",
        "Algunos conceptos previos: \n",
        "\n",
        "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
        "- `batch`: una fracción de la época. Se utilizan para entrenar mas rápidamente la red. (mas eficiente pasar n datos que uno en cada ejecución del backpropagation)\n",
        "\n",
        "Esta función está encargada de entrenar la red en una época. Para esto, por cada batch de la época actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
        "\n",
        "Observación: En algunos comentarios aparecerá el tamaño de los tensores entre corchetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "DV6YLt0oiicW"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Por cada batch del iterador de la época:\n",
        "    for batch in iterator:\n",
        "\n",
        "        # Extraemos el texto y los tags del batch que estamos procesado\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        # Reiniciamos los gradientes calculados en la iteración anterior\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text)\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "\n",
        "\n",
        "\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "        \n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizamos los parámetros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        # Actualizamos el loss y las métricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNcwKnAz5Hf"
      },
      "source": [
        "#### **Definimos la función de evaluación**\n",
        "\n",
        "Evalua el rendimiento actual de la red usando los datos de validación. \n",
        "\n",
        "Por cada batch de estos datos, calcula y reporta el loss y las métricas asociadas al conjunto de validación. \n",
        "Ya que las métricas son calculadas por cada batch, estas son retornadas promediadas por el número de batches entregados. (ver linea del return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "WsRuiUuHiicY"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            # Predecimos\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las métricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            # Actualizamos el loss y las métricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Xs-n9Y5yiica"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3MVf5H0A94"
      },
      "source": [
        "\n",
        "#### **Entrenamiento de la red**\n",
        "\n",
        "En este cuadro de código ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el número de épocas y luego por cada época, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez. \n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la función `init_weights`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK5lQqpviicf",
        "outputId": "e537d938-03b3-4910-acd1-8f86dfb88f3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.768 | Train f1: 0.04 | Train precision: 0.13 | Train recall: 0.03\n",
            "\t Val. Loss: 1.466 |  Val. f1: 0.00 |  Val. precision: 0.17 | Val. recall: 0.00\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.436 | Train f1: 0.04 | Train precision: 0.16 | Train recall: 0.02\n",
            "\t Val. Loss: 1.288 |  Val. f1: 0.04 |  Val. precision: 0.15 | Val. recall: 0.03\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.252 | Train f1: 0.16 | Train precision: 0.31 | Train recall: 0.11\n",
            "\t Val. Loss: 1.132 |  Val. f1: 0.27 |  Val. precision: 0.62 | Val. recall: 0.19\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.137 | Train f1: 0.28 | Train precision: 0.48 | Train recall: 0.20\n",
            "\t Val. Loss: 0.976 |  Val. f1: 0.36 |  Val. precision: 0.62 | Val. recall: 0.26\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.971 | Train f1: 0.39 | Train precision: 0.58 | Train recall: 0.30\n",
            "\t Val. Loss: 0.866 |  Val. f1: 0.46 |  Val. precision: 0.64 | Val. recall: 0.36\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.824 | Train f1: 0.48 | Train precision: 0.64 | Train recall: 0.38\n",
            "\t Val. Loss: 0.693 |  Val. f1: 0.61 |  Val. precision: 0.79 | Val. recall: 0.50\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.659 | Train f1: 0.60 | Train precision: 0.76 | Train recall: 0.49\n",
            "\t Val. Loss: 0.561 |  Val. f1: 0.69 |  Val. precision: 0.84 | Val. recall: 0.58\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.572 | Train f1: 0.69 | Train precision: 0.81 | Train recall: 0.61\n",
            "\t Val. Loss: 0.476 |  Val. f1: 0.70 |  Val. precision: 0.92 | Val. recall: 0.58\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.458 | Train f1: 0.77 | Train precision: 0.84 | Train recall: 0.71\n",
            "\t Val. Loss: 0.371 |  Val. f1: 0.81 |  Val. precision: 0.91 | Val. recall: 0.74\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.356 | Train f1: 0.86 | Train precision: 0.92 | Train recall: 0.80\n",
            "\t Val. Loss: 0.307 |  Val. f1: 0.88 |  Val. precision: 0.90 | Val. recall: 0.87\n"
          ]
        }
      ],
      "source": [
        "#Agregar early stop\n",
        "best_valid_loss = float('inf')\n",
        "best_train_loss = float('inf')\n",
        "\n",
        "arrayTrainLoss = []\n",
        "arrayValidLoss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, train_iterator, optimizer, criterion)\n",
        "\n",
        "    # Evaluar (valid = validación)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    #Nuevo **\n",
        "    arrayTrainLoss.append(train_loss)\n",
        "    arrayValidLoss.append(valid_loss)\n",
        "\n",
        "  #Acá nos aseguramos de que entrene al menos 4 épocas antes de detener el entrenamiento.\n",
        "    if epoch < 5:\n",
        "      if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #nuevo\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "      else :\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "\n",
        "  #Early stop, ve que no vaya en aumento, según el avg de las últimas 4 épocas\n",
        "    else:\n",
        "      if train_loss < np.mean(arrayTrainLoss[-4:]) and valid_loss > np.mean(arrayValidLoss[-4:]):\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )\n",
        "        print('Early Stop')\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        best_valid_loss = valid_loss\n",
        "        #nuevo\n",
        "        best_train_loss = train_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(\n",
        "            f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "        )\n",
        "        print(\n",
        "            f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcZPraG-9duO"
      },
      "source": [
        "**Importante**: Recuerden que el último modelo entrenado no es el mejor (probablemente esté *overfitteado*), si no el que guardamos con la menor loss del conjunto de validación. Este problema lo pueden solucionar con *early stopping*.\n",
        "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y27CNYfrjtQ-",
        "outputId": "2652e1ca-f6fb-46c4-ef22-3c47cd9d726f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "oLuqFKFR9duO"
      },
      "outputs": [],
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBctQHTh0lxD"
      },
      "source": [
        "#### **Evaluamos el set de validación con el modelo final**\n",
        "\n",
        "Estos son los resultados de predecir el dataset de evaluación con el *mejor* modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0gVbP8yiicj",
        "outputId": "269c91dc-1d2a-462a-93e1-9549644f9e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val. Loss: 0.307 |  Val. f1: 0.88 | Val. precision: 0.90 | Val. recall: 0.87\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, valid_iterator, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "### **Predecir datos para la competencia**\n",
        "\n",
        "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, vamos a predecir las etiquetas que serán evaluadas en la competencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "1RBs3UU4wLk3"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "                predictions.append(['EOS', 'EOS'])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, test_iterator, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcmEqmemHqJD",
        "outputId": "be1188b6-dd94-4cf9-8f93-670f900c2f7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['FENITOÍNA', 'B-ACTVPRNCP'],\n",
              " ['250', 'O'],\n",
              " ['MG/5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['2', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAMUSCULAR', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['METRONIDAZOL', 'B-ACTVPRNCP'],\n",
              " ['500', 'O'],\n",
              " ['MG/100', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['100', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['1', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['PARENTERAL', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['3', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['DEXAMETASONA', 'B-ACTVPRNCP'],\n",
              " ['4', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['2', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['METAMIZOL', 'B-ACTVPRNCP'],\n",
              " ['SÓDICO', 'B-ACTVPRNCP'],\n",
              " ['1', 'O'],\n",
              " ['G/2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['3000', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SODIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['10', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['20', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['4', 'O'],\n",
              " ['G', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['ISOSORBIDE', 'B-ACTVPRNCP'],\n",
              " ['DINITRATO', 'O'],\n",
              " ['10', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['4', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['2', 'I-DURATION'],\n",
              " ['meses', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['PREDNISOLONA', 'B-ACTVPRNCP'],\n",
              " ['1', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SUSPENSIÓN', 'B-ADMIN'],\n",
              " ['OFTÁLMICA', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['1', 'O'],\n",
              " ['GOTAS', 'B-ADMIN'],\n",
              " ['OFTÁLMICA', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['2', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['7', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['GENTAMICINA', 'B-ACTVPRNCP'],\n",
              " ['80', 'O'],\n",
              " ['MG/2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['13', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['EN', 'O'],\n",
              " ['BOLO', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['AMOXICILINA', 'B-ACTVPRNCP'],\n",
              " ['400', 'O'],\n",
              " ['MG/5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['+', 'B-ADMIN'],\n",
              " ['ACIDO', 'I-ADMIN'],\n",
              " ['CLAVULANICO', 'O'],\n",
              " ['57', 'O'],\n",
              " ['MG/5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SUSPENSION', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['35', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['dos', 'O'],\n",
              " ['veces', 'O'],\n",
              " ['al', 'O'],\n",
              " ['día', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['ATRACURIO', 'B-ACTVPRNCP'],\n",
              " ['BESILATO', 'O'],\n",
              " ['25', 'O'],\n",
              " ['MG/2,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['para', 'B-DURATION'],\n",
              " ['<unk>', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['POTASIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['600', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['LIBERACIÓN', 'I-ADMIN'],\n",
              " ['PROLONGADA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['OTRA', 'O'],\n",
              " ['VÍA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['x', 'B-DURATION'],\n",
              " ['SNE', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['POLIETILENGLICOL', 'B-ACTVPRNCP'],\n",
              " ['3350', 'O'],\n",
              " ['5', 'O'],\n",
              " ['G', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCION', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['5', 'O'],\n",
              " ['G', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LORAZEPAM', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['4', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['0,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['KETAMINA', 'B-ACTVPRNCP'],\n",
              " ['500', 'O'],\n",
              " ['MG/10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['8', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAMUSCULAR', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LEVOTIROXINA', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MCG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['75', 'O'],\n",
              " ['¿G', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['2', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['GENTAMICINA', 'B-ACTVPRNCP'],\n",
              " ['80', 'O'],\n",
              " ['MG/2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['HIDRALAZINA', 'B-ACTVPRNCP'],\n",
              " ['50', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['75', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['6', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CALCIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'B-ACTVPRNCP'],\n",
              " ['10', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LACTULOSA', 'B-ACTVPRNCP'],\n",
              " ['65%', 'O'],\n",
              " ['JARABE', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['200', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['25', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['TRAMADOL', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['0,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['12', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['3', 'I-DURATION'],\n",
              " ['meses', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['AMIKACINA', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MG/2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['1,5', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['QUETIAPINA', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['2,5', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['-', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['-', 'O'],\n",
              " ['150mg', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CEFADROXILO', 'B-ACTVPRNCP'],\n",
              " ['500', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['CÁPSULA', 'B-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['CÁPSULA', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['tres', 'O'],\n",
              " ['veces', 'O'],\n",
              " ['al', 'O'],\n",
              " ['día', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['PREDNISONA', 'B-ACTVPRNCP'],\n",
              " ['20', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['0,5', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['14', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['METAMIZOL', 'B-ACTVPRNCP'],\n",
              " ['SÓDICO', 'B-ACTVPRNCP'],\n",
              " ['1', 'O'],\n",
              " ['G/2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['6', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAMUSCULAR', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['50', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['LIOFILIZADO', 'I-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCIÓN', 'I-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['12', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['30', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SALES', 'B-ACTVPRNCP'],\n",
              " ['DE', 'O'],\n",
              " ['REHIDRATACIÓN', 'O'],\n",
              " ['60', 'O'],\n",
              " ['MEQ', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCIÓN', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['SOBRES', 'O'],\n",
              " ['1', 'O'],\n",
              " ['SOBRE', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['4', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['4', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SODIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['10', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['20', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SALBUTAMOL', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MCG/DOSIS', 'O'],\n",
              " ['INHALADOR', 'O'],\n",
              " ['200', 'O'],\n",
              " ['DOSIS', 'O'],\n",
              " ['2', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['INHALATORIA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LOSARTÁN', 'O'],\n",
              " ['50', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['RECUBIERTO', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['12', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SODIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['0,9', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['MATRAZ', 'O'],\n",
              " ['1000', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ml', 'O'],\n",
              " ['/', 'O'],\n",
              " ['25', 'O'],\n",
              " ['h', 'O'],\n",
              " ['(', 'O'],\n",
              " ['Velocidad', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ml/h', 'O'],\n",
              " [')INTRAVENOSA', 'B-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['POTASIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['10', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ml', 'O'],\n",
              " ['/', 'O'],\n",
              " ['24', 'O'],\n",
              " ['h', 'O'],\n",
              " ['(', 'O'],\n",
              " ['Velocidad', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ml/h', 'O'],\n",
              " [')INTRAVENOSA', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['HALOPERIDOL', 'B-ACTVPRNCP'],\n",
              " ['5', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['INTRAVASCULAR', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['ERITROPOYETINA', 'B-ACTVPRNCP'],\n",
              " ['4000', 'O'],\n",
              " ['UI/mL', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['SUBCUTÁNEA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['7', 'I-PERIODICITY'],\n",
              " ['dias', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['15', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['ATRACURIO', 'B-ACTVPRNCP'],\n",
              " ['BESILATO', 'O'],\n",
              " ['25', 'O'],\n",
              " ['MG/2,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['2,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['250', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['diaria', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CIANOCOBALAMINA', 'O'],\n",
              " ['0,1', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['3', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAMUSCULAR', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['<unk>', 'O'],\n",
              " ['UI', 'O'],\n",
              " ['SOLUCION', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['GOTAS', 'I-ADMIN'],\n",
              " ['10', 'O'],\n",
              " ['GOTAS', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['10', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['al', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['IBUPROFENO', 'B-ACTVPRNCP'],\n",
              " ['200', 'O'],\n",
              " ['MG/5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SUPENSIÓN', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['2,5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LEVOTIROXINA', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MCG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['0,75', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['POLIETILENGLICOL', 'B-ACTVPRNCP'],\n",
              " ['3350', 'O'],\n",
              " ['5', 'O'],\n",
              " ['G', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCION', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['3', 'O'],\n",
              " ['SOBRE', 'B-ADMIN'],\n",
              " ['OTRA', 'O'],\n",
              " ['VÍA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['ÁCIDO', 'B-ACTVPRNCP'],\n",
              " ['VALPROICO', 'O'],\n",
              " ['375', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['(10', 'O'],\n",
              " ['mg/gota)', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['GOTAS', 'I-ADMIN'],\n",
              " ['ORALES', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['25', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['15', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CEFAZOLINA', 'B-ACTVPRNCP'],\n",
              " ['1', 'O'],\n",
              " ['G', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['LIOFILIZADO', 'I-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCIÓN', 'I-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['1', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['LORAZEPAM', 'O'],\n",
              " ['1', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['<unk>', 'B-ADMIN'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['<unk>', 'O'],\n",
              " ['al', 'O'],\n",
              " ['acostarse', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['TIAMINA', 'B-ACTVPRNCP'],\n",
              " ['30', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['8', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['diaria', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SODIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['0,9', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['MATRAZ', 'O'],\n",
              " ['500', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['2', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SOLUCIÓN', 'B-ACTVPRNCP'],\n",
              " ['GLUCOSALINA', 'B-ACTVPRNCP'],\n",
              " ['ISOTÓNICA', 'O'],\n",
              " ['1.000', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['INYECTABLE', 'B-ADMIN'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['1000', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['3', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['PARENTERAL', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['METFORMINA', 'B-ACTVPRNCP'],\n",
              " ['850', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['2', 'I-DURATION'],\n",
              " ['meses', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['PARENTERAL', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['40', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-ADMIN'],\n",
              " ['1', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CEFAZOLINA', 'B-ACTVPRNCP'],\n",
              " ['1', 'O'],\n",
              " ['G', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['LIOFILIZADO', 'I-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SOLUCIÓN', 'I-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['500', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['<unk>', 'O'],\n",
              " ['UI', 'O'],\n",
              " ['SOLUCION', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['GOTAS', 'I-ADMIN'],\n",
              " ['3', 'O'],\n",
              " ['GOTAS', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['15', 'I-PERIODICITY'],\n",
              " ['dias', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['SODIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'O'],\n",
              " ['0,9', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['MATRAZ', 'O'],\n",
              " ['500', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['250', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['<unk>', 'O'],\n",
              " ['100', 'O'],\n",
              " ['MG/5ML', 'O'],\n",
              " ['SOLUCION', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['0,5', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['24', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['50', 'O'],\n",
              " ['MG/10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['1', 'O'],\n",
              " ['FRASCO', 'O'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['dosis', 'O'],\n",
              " ['simple', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CALCIO', 'B-ACTVPRNCP'],\n",
              " ['CLORURO', 'B-ACTVPRNCP'],\n",
              " ['10', 'O'],\n",
              " ['%', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['10', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['2', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAVENOSA', 'O'],\n",
              " ['diaria', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['PREDNISONA', 'B-ACTVPRNCP'],\n",
              " ['5', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['2', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['RECUBIERTO', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['12', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['3', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['<unk>', 'B-ACTVPRNCP'],\n",
              " ['<unk>', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['1', 'O'],\n",
              " ['<unk>', 'B-ADMIN'],\n",
              " ['SUBCUTÁNEA', 'O'],\n",
              " ['tres', 'O'],\n",
              " ['veces', 'O'],\n",
              " ['al', 'O'],\n",
              " ['día', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['METFORMINA', 'B-ACTVPRNCP'],\n",
              " ['850', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['0,5', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['15', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['FUROSEMIDA', 'B-ACTVPRNCP'],\n",
              " ['20', 'O'],\n",
              " ['MG/ML', 'O'],\n",
              " ['SOLUCIÓN', 'B-ADMIN'],\n",
              " ['INYECTABLE', 'I-ADMIN'],\n",
              " ['AMPOLLA', 'O'],\n",
              " ['1', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['2', 'O'],\n",
              " ['UNIDAD', 'O'],\n",
              " ['INTRAMUSCULAR', 'O'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CEFADROXILO', 'B-ACTVPRNCP'],\n",
              " ['250', 'O'],\n",
              " ['MG/5', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['POLVO', 'B-ADMIN'],\n",
              " ['PARA', 'I-ADMIN'],\n",
              " ['SUSPENSIÓN', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['FRASCO', 'O'],\n",
              " ['60', 'O'],\n",
              " ['ML', 'O'],\n",
              " ['Suministro', 'O'],\n",
              " ['inmediato', 'O'],\n",
              " ['primera', 'O'],\n",
              " ['vez.', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['12', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['EOS', 'EOS'],\n",
              " ['CLOZAPINA', 'B-ACTVPRNCP'],\n",
              " ['100', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['<unk>', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['ORAL', 'B-ADMIN'],\n",
              " ['diaria', 'O'],\n",
              " ['0', 'O'],\n",
              " ['-', 'O'],\n",
              " ['0', 'O'],\n",
              " ['-', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['mg', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['y', 'O'],\n",
              " ['<unk>', 'O'],\n",
              " ['EOS', 'EOS'],\n",
              " ['AMOXICILINA', 'B-ACTVPRNCP'],\n",
              " ['500', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['+', 'B-ADMIN'],\n",
              " ['ÁCIDO', 'I-ADMIN'],\n",
              " ['CLAVULÁNICO', 'O'],\n",
              " ['125', 'O'],\n",
              " ['MG', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['1', 'O'],\n",
              " ['COMPRIMIDO', 'B-ADMIN'],\n",
              " ['RECUBIERTO', 'I-ADMIN'],\n",
              " ['ORAL', 'I-ADMIN'],\n",
              " ['cada', 'B-PERIODICITY'],\n",
              " ['8', 'I-PERIODICITY'],\n",
              " ['horas', 'I-PERIODICITY'],\n",
              " ['durante', 'B-DURATION'],\n",
              " ['24', 'I-DURATION'],\n",
              " ['dias', 'I-DURATION'],\n",
              " ['EOS', 'EOS'],\n",
              " ['DIAZEPAM', 'B-ACTVPRNCP'],\n",
              " ...]"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### **Generar el archivo para la submission**\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "RPfZkjJGkWyq"
      },
      "outputs": [],
      "source": [
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for i, (word, tag) in enumerate(predictions[:-1]):\n",
        "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
        "    else: \n",
        "      if i == len(predictions[:-1])-1:\n",
        "        f.write(word + ' ' + tag)\n",
        "      else: f.write(word + ' ' + tag + '\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
